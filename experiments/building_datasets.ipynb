{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778fc545",
   "metadata": {},
   "source": [
    "## Importing BindingDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell imports bindingdb data\n",
    "\n",
    "from data_interfaces.access_bindingdb import bindingdb_records\n",
    "import os\n",
    "from download_file import download\n",
    "from zipfile import ZipFile\n",
    "\n",
    "bdb_download_url= \"https://www.bindingdb.org/bind/downloads/BindingDB_All_2021m11.tsv.zip\"\n",
    "#if the affinities are already stored from previous run, it just reads the cached (pickled) data\n",
    "bdb = bindingdb_records()\n",
    "if (os.path.exists(\"./data_interfaces/cached_data/bindingdb2021m11_bin_Ki_1uM_30uM.pkl\")):\n",
    "    bdb.read_from_pickle(\"./data_interfaces/cached_data/bindingdb2021m11_bin_Ki_1uM_30uM.pkl\")\n",
    "else:\n",
    "    if os.path.exists(\"data_sources/bindingdb/db2021m11.tsv\"):\n",
    "        pass\n",
    "    else:\n",
    "        if not os.path.exists(\"data_sources/bindingdb/\"):\n",
    "            os.makedirs(\"data_sources/bindingdb/\")\n",
    "        print(\"downloading bindingdb file...\")\n",
    "        download(bdb_download_url, \"./data_sources/\")\n",
    "        print(\"extracting bindingdb file...\")\n",
    "        zfilename = os.path.split(bdb_download_url)[1]\n",
    "        bdb_version = zfilename.split(\"_\")[-1].split(\".\")[0]\n",
    "        with ZipFile(\"./data_sources/\"+zfilename,\"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"./data_sources/\")\n",
    "        os.rename(\"./data_sources/BindingDB_All.tsv\",\"./data_sources/bindingdb/db2021m11.tsv\")        \n",
    "    bdb.read_from_csv(\"data_sources/bindingdb/db2021m11.tsv\")\n",
    "    bdb.binarize_db(l_threshold=1000,h_threshold=30000)\n",
    "    if not os.path.exists(\"./data_interfaces/cached_data/\"):\n",
    "        os.makedirs(\"./data_interfaces/cached_data/\")\n",
    "    bdb.save_to_pickle(\"./data_interfaces/cached_data/bindingdb2021m11_bin_Ki_1uM_30uM.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad18e8b",
   "metadata": {},
   "source": [
    "## Building testset1 (difficult testset)\n",
    "\n",
    "Here we find cases where a domain interacts with a compound (when it is on a single domain protein), But same domain doesn't interact with that compound when the domain is on a protein with other domains or other unannoated regions. \n",
    "\n",
    "we first collect all such cases that could be collected using data from BindingDB and pfam-A\n",
    "\n",
    "Secondly, we merge the proteins that are similar in their combination/arrangement of domains to make sure we are dealing with different proteins and not proteins that are just a slightly modified version of each other.\n",
    "\n",
    "testset1 then is a collection of these non-redundant protein-compound pairs that are involved in these 'context-sensitive' interactions. context-sensitive in the sense that the interaction doesn't depend only on the domain of interest but also on the rest of the protein.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645d03a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502d20452f854cbe9ed85eb5e1e96ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "collecting domain annotations:   0%|          | 0/5750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results before merging 'similar' proteins \n",
      "------------------------------------------\n",
      "number domain-compound pairs with positive interactions:  18229\n",
      "number of domains involved:  89\n",
      "number of compounds involved:  18088\n",
      "number domain-compound pairs with context-sensitive interactions:  660\n",
      "number of domains involved:  17\n",
      "number of comnpounds involved:  660\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "After merging similar proteins\n",
      "------------------------------------------\n",
      "number of domain-ligand pairs:  256\n",
      "number of number of domains involved:  9\n",
      "number of number of compounds involved:  256\n",
      "number of resulting protin-compound pairs:  739\n",
      "number of positive pairs:  346\n",
      "number of negative pairs:  393\n",
      "number of protins:  67\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from data_interfaces.access_pfam import pfam_records\n",
    "# import importlib\n",
    "# import fetch_data\n",
    "# importlib.reload(fetch_data.access_pfam)\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# then we find all proteins that have that domain and they are divided into pos, neg and unk based on if they interact with that drug or not\n",
    "# we only have a case when there is an element in neg \n",
    "# in that case the domain-drug pair should be added to the pairs and pos_cases[(domain, drug)] is the set of all proteins that have that domain and do interact and neg_cases[(domain, drug)] is the set of proteins with that domain that don't interact. unk_cases will be the set of those that have that domain buut their interaction is not known. But in all of these three dicts only we have keys for the conflicting cases meaning those that have a single domain positive interaction and at least one protein with negative interaction\n",
    "\n",
    "# first we find all single-domain proteins\n",
    "pfam_all = pfam_records(prot_list=bdb.get_all_prots(), use_cache_file=\"data_interfaces/cached_data/pfam_cache.pkl\")\n",
    "single_dom_prots = pfam_all.get_singledom_prots()\n",
    "\n",
    "pos_dom_cmp = set() # interacting domain-compound pairs\n",
    "dci_doms = set()\n",
    "dci_cmps = set()\n",
    "\n",
    "# if there is a positive interaction between a single-domain protein and a compound, we assume an interaction between domain and compound. We find all interacting domain-compound pairs with this approach\n",
    "for p in single_dom_prots:\n",
    "    dom = pfam_all.get_domainlist_for_prot(p)[0]\n",
    "    ligs = bdb.get_ligands_of(p)\n",
    "    for lig in ligs:\n",
    "        pos_dom_cmp.add((dom,lig))\n",
    "        dci_doms.add(dom)\n",
    "        dci_cmps.add(lig)\n",
    "        \n",
    "\n",
    "        \n",
    "pos_cases = dict() # positive examples (proteins) for domain-compound pair\n",
    "neg_cases = dict() # negative examples (proteins) for domain-compound pair\n",
    "unk_cases = dict() # examples (proteins) with unknown interaction for a domain-compound pair\n",
    "\n",
    "dff_dom_cmp = set() # domain-compoud pairs that have context-senstive interactions\n",
    "dff_doms = set() # domains involved in context-sensitive domain-compound pairs\n",
    "dff_cmps = set() # compounds invloved in context-sensitive domain-compound pairs\n",
    "\n",
    "dff_pos_pairs = set() # difficult protein-compound pairs - positive\n",
    "dff_neg_pairs = set() # difficult protein-compound pairs - negative            \n",
    "                \n",
    "for (dom,cmp) in pos_dom_cmp:\n",
    "    q_set = pfam_all.get_proteins_with(dom)\n",
    "    negatives = []\n",
    "    positives = []\n",
    "    unknowns = []\n",
    "    for q in q_set:\n",
    "        inn = bdb.get_bin_interaction((q,cmp))\n",
    "        if type(inn)==bool:\n",
    "            if inn:\n",
    "                positives.append(q)\n",
    "            else:\n",
    "                negatives.append(q)\n",
    "        else:\n",
    "            unknowns.append(q)\n",
    "\n",
    "    pos_cases[(dom, cmp)] = positives\n",
    "    neg_cases[(dom, cmp)] = negatives \n",
    "    unk_cases[(dom, cmp)] = unknowns\n",
    "    if len(negatives)>0:\n",
    "        dff_dom_cmp.add((dom, cmp))\n",
    "        dff_doms.add(dom)\n",
    "        dff_cmps.add(cmp)\n",
    "        for q in negatives:\n",
    "            dff_neg_pairs.add((q,cmp))\n",
    "        for q in positives:\n",
    "            dff_pos_pairs.add((q,cmp))\n",
    "\n",
    "\n",
    "            \n",
    "print(\"results before merging 'similar' proteins \")\n",
    "print(\"------------------------------------------\")\n",
    "print(\"number domain-compound pairs with positive interactions: \", len(pos_dom_cmp))\n",
    "print(\"number of domains involved: \", len(dci_doms))\n",
    "print(\"number of compounds involved: \", len(dci_cmps))\n",
    "print(\"number domain-compound pairs with context-sensitive interactions: \", len(dff_dom_cmp))\n",
    "print(\"number of domains involved: \", len (dff_doms))\n",
    "print(\"number of comnpounds involved: \", len (dff_cmps))\n",
    "print(\"------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "### here we remove conflicting cases: where 'similar' proteins have found one with negative and one with positive interaction with a drug\n",
    "### and remove redundancy within positive and negatives \n",
    "### to do this:\n",
    "### for each domain-compound pair:\n",
    "# we see if there is any intersection between the positive cases and negative cases using our segment string method\n",
    "# if there is not any, then we reduce the positve set and negative set separately and then when we have our positives and negatives that we then add to the testset1 postive and negative pairs\n",
    "\n",
    "\n",
    "dff_nred_pos_pairs = set() # non-redundant positive portein-compound pairs\n",
    "dff_nred_neg_pairs = set() # non-redundant negative portein-compound pairs\n",
    "dc_pairs_wconflict = set()\n",
    "\n",
    "\n",
    "for (dom,cmp) in dff_dom_cmp:\n",
    "    pos_pfset = pfam_all.extract_subset(pos_cases[(dom,cmp)])\n",
    "#     print(pos_pfset)\n",
    "    neg_pfset = pfam_all.extract_subset(neg_cases[(dom,cmp)])\n",
    "    # find conflicting cases where 'similar' proteins are in the positives and negatives\n",
    "    shared_neg_pos  = pos_pfset.same_prots(neg_pfset)\n",
    "    if len(shared_neg_pos) > 0:\n",
    "        dc_pairs_wconflict.add((dom,cmp))\n",
    "    else:\n",
    "        #remove redundancy within positive examples and within negative examples\n",
    "        pref = dict()\n",
    "        for p in pos_cases[(dom,cmp)]:\n",
    "            ### when removing redundant proteins, we prefer those with which there is higher number of records for them with the current compound\n",
    "            pref[p] = len(bdb.get_records_for_pair((p,cmp)))\n",
    "        pos_nred = pos_pfset.reduce_to_nonredunant(prot_preference_score=pref)\n",
    "        \n",
    "        pref = dict()\n",
    "        for p in neg_cases[(dom,cmp)]:\n",
    "            ### when removing redundant proteins, we prefer those with which there is higher number of records for them with the current compound\n",
    "            pref[p] = len(bdb.get_records_for_pair((p,cmp))) \n",
    "        neg_nred = neg_pfset.reduce_to_nonredunant(prot_preference_score=pref)\n",
    "        \n",
    "        for p in pos_nred:\n",
    "            dff_nred_pos_pairs.add((p,cmp))\n",
    "        for p in neg_nred:\n",
    "            dff_nred_neg_pairs.add((p,cmp))\n",
    "\n",
    "\n",
    "dff_nred_dc_pairs = dff_dom_cmp - dc_pairs_wconflict # difficult dc pairs remaining after removing conflicting (those that have similar proteins in positive and negative side)\n",
    "\n",
    "\n",
    "\n",
    "dff_nred_doms = set() # domains involved in the remaining domain-compound pairs after removal of conflicts\n",
    "dff_nred_cmps = set() # compounds involved in the remaining domain-compound pairs after removal of conflicts\n",
    "for dom, cmp in dff_nred_dc_pairs:\n",
    "    dff_nred_doms.add(dom)\n",
    "    dff_nred_cmps.add(cmp)\n",
    "\n",
    "    \n",
    "    \n",
    "# the set of difficult and non-redundant postive and negative protein-compound pairs will build testset1\n",
    "dff_nred_pairs = dff_nred_pos_pairs|dff_nred_neg_pairs # protein-compound pairs in testset1\n",
    "\n",
    "dff_nred_prots =set() #set of proteins involved in testset1. we already have the set of compounds involved from domain-compound pairs\n",
    "for prot, cmp in dff_nred_pairs:\n",
    "    dff_nred_prots.add(prot)\n",
    "\n",
    "print (\"\\nAfter merging similar proteins\")\n",
    "print(\"------------------------------------------\")\n",
    "print (\"number of domain-ligand pairs: \",len(dff_nred_dc_pairs))\n",
    "print (\"number of number of domains involved: \",len(dff_nred_doms))\n",
    "print (\"number of number of compounds involved: \",len(dff_nred_cmps))\n",
    "print (\"number of resulting protin-compound pairs: \", len(dff_nred_pairs))\n",
    "print (\"number of positive pairs: \", len(dff_nred_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(dff_nred_neg_pairs))\n",
    "print (\"number of protins: \", len(dff_nred_prots))\n",
    "print(\"------------------------------------------\\n\")\n",
    "\n",
    "testset1_pos_pairs = dff_nred_pos_pairs\n",
    "testset1_neg_pairs  = dff_nred_neg_pairs\n",
    "testset1_pairs = dff_nred_pairs\n",
    "testset1_prots = dff_nred_prots\n",
    "testset1_cmps = dff_nred_cmps\n",
    "\n",
    "from build_dataset import save_dataset_csv\n",
    "if not os.path.exists(\"./datasets/\"):\n",
    "    os.makedirs(\"./datasets/\")\n",
    "save_dataset_csv(testset1_pairs,bdb,\"datasets/testset1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba6571f",
   "metadata": {},
   "source": [
    "## Building testset2 (proteins and compounds from testset1)\n",
    "\n",
    "testset2 is created with the assumption that there is something inherently difficult in the proteins and compounds in the testset1. we want the testset2 to  be a superset of testset1 and have similar proportion of positives and negatives to testset1, but also represent the whole interactome of proteins and compounds in testset1\n",
    "\n",
    "Alternatively we could choose to:\n",
    "1. to include testset1 in testset2 or exclude it:For now we choose to include it\n",
    "2. to sample randomly for fixing proportions or to have some bias in their selection. For example towards those proteins and drugs that are involved in more pairs than others: For now we just randomly sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf906168",
   "metadata": {},
   "outputs": [],
   "source": [
    "protx_prot_cmp_pairs = set()# negative protein-compound pairs that the protein is in testset1\n",
    "cmpx_prot_cmp_pairs = set() # negative protein-compound pairs where the compound is in the compound set of testset1\n",
    "\n",
    "ext_prots = set()\n",
    "ext_cmps = set()\n",
    "\n",
    "\n",
    "\n",
    "for (prot,cmp) in bdb.get_all_bin_pairs():\n",
    "    if prot in testset1_prots:\n",
    "        protx_prot_cmp_pairs.add((prot,cmp))\n",
    "    if cmp in testset1_cmps:\n",
    "        cmpx_prot_cmp_pairs.add((prot,cmp))\n",
    "\n",
    "\n",
    "\n",
    "ext_prot_cmp_pairs = protx_prot_cmp_pairs | cmpx_prot_cmp_pairs\n",
    "\n",
    "ext_prots = set()\n",
    "ext_cmps = set()\n",
    "ext_pos_pairs = set()\n",
    "ext_neg_pairs = set()\n",
    "\n",
    "for (prot, cmp) in ext_prot_cmp_pairs:\n",
    "    ext_cmps.add(cmp)\n",
    "    ext_prots.add(prot)\n",
    "    if bdb.get_bin_interaction((prot,cmp)):\n",
    "        ext_pos_pairs.add((prot,cmp))\n",
    "    else:\n",
    "        ext_neg_pairs.add((prot,cmp))\n",
    "        \n",
    "        \n",
    "print (\"Extended pairs before resampling\")\n",
    "print (\"number of resulting protin-compound pairs: \", len(ext_prot_cmp_pairs))\n",
    "print (\"number of pair from extending by proteins: \", len(protx_prot_cmp_pairs))\n",
    "print (\"number of pair from extending by compounds: \", len(cmpx_prot_cmp_pairs))\n",
    "print (\"number of positive pairs: \", len(ext_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(ext_neg_pairs))\n",
    "print (\"number of protins: \", len(ext_prots))\n",
    "print (\"number of compounds: \", len(ext_cmps))\n",
    "\n",
    "\n",
    "# we want the testset2 to be a superset of testset1 but also have same postive-negative ratio and \n",
    "\n",
    "pos_neg_ratio = len(testset1_pos_pairs)/len(testset1_neg_pairs)\n",
    "\n",
    "target_neg_number  = int(len(ext_neg_pairs) * 0.5)\n",
    "target_pos_number = int(target_neg_number * pos_neg_ratio)\n",
    "\n",
    "n_pos_2samp = target_pos_number-len(testset1_pos_pairs)\n",
    "n_neg_2samp = target_neg_number-len(testset1_neg_pairs)\n",
    "\n",
    "pos_samp_pool = ext_pos_pairs-testset1_pos_pairs\n",
    "neg_samp_pool = ext_neg_pairs-testset1_neg_pairs\n",
    "\n",
    "import random\n",
    "\n",
    "sampd_pos = set(random.sample(list(pos_samp_pool), n_pos_2samp))\n",
    "sampd_neg = set(random.sample(list(neg_samp_pool), n_neg_2samp))\n",
    "\n",
    "testset2_pos_pairs = testset1_pos_pairs | sampd_pos\n",
    "testset2_neg_pairs = testset1_neg_pairs | sampd_neg\n",
    "\n",
    "\n",
    "testset2_pairs = testset2_pos_pairs | testset2_neg_pairs\n",
    "\n",
    "testset2_prots = set()\n",
    "testset2_cmps = set()\n",
    "\n",
    "for (prot,cmp) in testset2_pairs:\n",
    "    testset2_prots.add(prot)\n",
    "    testset2_cmps.add(cmp)\n",
    "\n",
    "print (\"\\nExtended pairs after resampling (testset2)\")\n",
    "print (\"number of protein-compound pairs: \", len(testset2_pairs))\n",
    "print (\"number of positive pairs: \", len(testset2_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(testset2_neg_pairs))\n",
    "print (\"number of proteins: \", len(testset2_prots))\n",
    "print (\"number of compounds: \", len(testset2_cmps))\n",
    "\n",
    "from build_dataset import save_dataset_csv\n",
    "if not os.path.exists(\"./datasets/\"):\n",
    "    os.makedirs(\"./datasets/\")\n",
    "save_dataset_csv(testset2_pairs,bdb,\"datasets/testset2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0cee5",
   "metadata": {},
   "source": [
    "# Building testset3\n",
    "testset3 is intended to be a random sample of all pairs in bindingdb while keeping the ratio between positives and negatives to be the same as their ratio in testset1.\n",
    "This dataset also have some importance because it is supposed to be a standard and unbiased way of evaluating predictors \n",
    "we have some choices here to make:\n",
    "1- how big the sample should be so it is both representative of a typical outcome of a prediction, not being accused of being based on luck, while at the same time leaving an adequate number of pairs for training (negative pairs are limiting here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = bdb.get_all_bin_pairs()\n",
    "all_pos_pairs = set()\n",
    "all_neg_pairs = set()\n",
    "all_prots = set()\n",
    "all_compounds = set()\n",
    "\n",
    "for (prot,cmp) in all_pairs:\n",
    "    all_prots.add(prot)\n",
    "    all_compounds.add(cmp)\n",
    "    if bdb.get_bin_interaction((prot, cmp)):\n",
    "        all_pos_pairs.add((prot,cmp))\n",
    "    else:\n",
    "        all_neg_pairs.add((prot,cmp))\n",
    "        \n",
    "print (\"\\nAll pairs before resampling:\")\n",
    "print (\"number of protein-compound pairs: \", len(all_pairs))\n",
    "print (\"number of proteins: \", len(all_prots))\n",
    "print (\"number of compounds: \", len(all_compounds))\n",
    "print (\"number of positive pairs: \", len(all_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(all_neg_pairs))\n",
    "\n",
    "pos_neg_ratio = len(testset1_pos_pairs)/len(testset1_neg_pairs)\n",
    "testset3_target_neg_number  = int(len(all_neg_pairs) * 0.2)\n",
    "testset3_target_pos_number = int(testset3_target_neg_number * pos_neg_ratio)\n",
    "\n",
    "import random\n",
    "\n",
    "testset3_pos_pairs = set(random.sample(list(all_pos_pairs), testset3_target_pos_number))\n",
    "testset3_neg_pairs = set(random.sample(list(all_neg_pairs), testset3_target_neg_number))\n",
    "testset3_pairs = testset3_pos_pairs | testset3_neg_pairs\n",
    "\n",
    "testset3_prots= set()\n",
    "testset3_compounds= set()\n",
    "for (prot, cmp) in testset3_pairs:\n",
    "    testset3_prots.add(prot)\n",
    "    testset3_compounds.add(cmp)\n",
    "\n",
    "print (\"\\ntestset3: (20% sample of all negatives)\")\n",
    "print (\"number of protein-compound pairs: \", len(testset3_pairs))\n",
    "print (\"number of proteins: \", len(testset3_prots))\n",
    "print (\"number of compounds: \", len(testset3_compounds))\n",
    "print (\"number of positive pairs: \", len(testset3_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(testset3_neg_pairs))\n",
    "\n",
    "\n",
    "from build_dataset import save_dataset_csv\n",
    "if not os.path.exists(\"./datasets/\"):\n",
    "    os.makedirs(\"./datasets/\")\n",
    "save_dataset_csv(testset3_pairs,bdb,\"datasets/testset3.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9f64b",
   "metadata": {},
   "source": [
    "## Combined testset (for exclusion from training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combtest_neg_pairs = (testset1_neg_pairs | testset2_neg_pairs | testset3_neg_pairs)\n",
    "combtest_pos_pairs = (testset1_pos_pairs | testset2_pos_pairs | testset3_pos_pairs)\n",
    "combtest_pairs = combtest_pos_pairs | combtest_neg_pairs\n",
    "\n",
    "\n",
    "combtest_pairs_prots= set()\n",
    "combtest_pairs_compounds= set()\n",
    "for (prot, cmp) in combtest_pairs:\n",
    "    combtest_pairs_prots.add(prot)\n",
    "    combtest_pairs_compounds.add(cmp)\n",
    "\n",
    "print (\"\\nremaining pairs (not in testset1,2 or 3):\")\n",
    "print (\"number of protein-compound pairs: \", len(combtest_pairs))\n",
    "print (\"number of proteins: \", len(combtest_pairs_prots))\n",
    "print (\"number of compounds: \", len(combtest_pairs_compounds))\n",
    "print (\"number of positive pairs: \", len(combtest_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(combtest_neg_pairs))\n",
    "\n",
    "\n",
    "from build_dataset import save_dataset_csv\n",
    "if not os.path.exists(\"./datasets/\"):\n",
    "    os.makedirs(\"./datasets/\")\n",
    "save_dataset_csv(combtest_pairs, bdb,\"datasets/combtestset123.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693038f6",
   "metadata": {},
   "source": [
    "## shared training set (remaining pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7362bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_pos_pairs  = all_pos_pairs - combtest_pos_pairs\n",
    "rem_pos_pairs  = all_pos_pairs - combtest_pos_pairs\n",
    "rem_pairs = rem_neg_pairs | rem_pos_pairs\n",
    "\n",
    "rem_pairs_prots = set()\n",
    "rem_pairs_compounds = set()\n",
    "\n",
    "for (prot, cmp) in rem_pairs:\n",
    "    rem_pairs_prots.add(prot)\n",
    "    rem_pairs_compounds.add(cmp)\n",
    "\n",
    "print (\"\\nremaining pairs (not in testset1,2 or 3):\")\n",
    "print (\"number of protein-compound pairs: \", len(rem_pairs))\n",
    "print (\"number of proteins: \", len(rem_pairs_prots))\n",
    "print (\"number of compounds: \", len(rem_pairs_compounds))\n",
    "print (\"number of positive pairs: \", len(rem_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(rem_neg_pairs))\n",
    "\n",
    "\n",
    "from build_dataset import save_dataset_csv\n",
    "\n",
    "# save_dataset_csv(rem_pairs, bdb,\"datasets/trainset_allrest.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pos_neg_ratio = len(testset1_pos_pairs)/len(testset1_neg_pairs)\n",
    "trainsr_target_pos_number = int(len(rem_neg_pairs) * pos_neg_ratio)\n",
    "\n",
    "import random\n",
    "trainsr_neg_pairs = rem_neg_pairs\n",
    "trainsr_pos_pairs = set(random.sample(list(rem_pos_pairs), trainsr_target_pos_number))\n",
    "\n",
    "trainsr_pairs = trainsr_pos_pairs | trainsr_neg_pairs\n",
    "\n",
    "trainsr_prots= set()\n",
    "trainsr_compounds= set()\n",
    "for (prot, cmp) in testset3_pairs:\n",
    "    trainsr_prots.add(prot)\n",
    "    trainsr_compounds.add(cmp)\n",
    "\n",
    "print (\"\\ntraining set with same pos-neg ratio as testsets\")\n",
    "print (\"number of protein-compound pairs: \", len(trainsr_pairs))\n",
    "print (\"number of proteins: \", len(trainsr_prots))\n",
    "print (\"number of compounds: \", len(trainsr_compounds))\n",
    "print (\"number of positive pairs: \", len(trainsr_pos_pairs))\n",
    "print (\"number of negative pairs: \", len(trainsr_neg_pairs))\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(\"./datasets/\"):\n",
    "    os.makedirs(\"./datasets/\")\n",
    "save_dataset_csv(trainsr_pairs,bdb,\"datasets/trainset_same_ratio.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
